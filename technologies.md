Technologies used in our Waupaca Project

I. For Data Cleaning, Processing, and Analysis

    Jupyter Notebook – we will use this open source web application to create and share documents that contain our code, some visualizations, and narrative.

    Python – we will use python to read and extract data from our csv files

    Pandas - will be use to clean, process, and perform exploratory analysis on our dataset.

II. Database Storage:

      Postgres db - is the database we will use to display the process data

III. Machine Learning models:

        SciKitLearn – will be use in our supervised learning model for classification, regression, clustering and dimensionality reduction.

        Matplotlib –  will be use for plotting and visualizing the data in various forms.

        TensorFlow –  we will use tensorflow to train and test our neural network model

        Numpy –  we will use numpy for our mathematical, logical, sorting and some basic statistical operation.

        Sklearn – we will use this tools to implement the Leanier Regression model.

IV. Tableau Desktop
Tableau will be use to carry on further analysis on our dataset, which will include interactive visualization, stories of our dataset, and a dashboard.
